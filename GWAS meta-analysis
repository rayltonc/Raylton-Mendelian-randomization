##AWIGen
METAL_AWIGen <- clumped_AWIGenresults %>%
  rename(
    SNP = rsid,
    REF_ALLELE = ref_allele,     
    OTHER_ALLELE = other_allele, 
    BETA = effect_size,
    PVALUE = pval,
    SE = std_error
  ) %>%
  # Calculate Variance and Weight
  mutate(
    N = 10775         # Add sample size column
  )

head (METAL_AWIGen)

#####Save the Data File
write.table(METAL_AWIGen, file = "METAL_AWIGen.txt", 
            sep = "\t", row.names = FALSE, quote = FALSE)

###GIANT
METAL_GIANT <- clumped_results_GIANT %>%
  rename(
    SNP = rsid,
    REF_ALLELE = ref_allele,     
    OTHER_ALLELE = other_allele, 
    BETA = effect_size,
    PVALUE = pval,
    SE = std_error
  ) %>%
  # Calculate Variance and Weight
  mutate(
    N = 681275         # Add sample size column
  )

head (METAL_GIANT)

#####Save the Data File
write.table(METAL_GIANT, file = "METAL_GIANT.txt", 
            sep = "\t", row.names = FALSE, quote = FALSE)

###standardising p-values

# Load datasets
dataset1 <- read.table("METAL_GIANT.txt", header = TRUE)
dataset2 <- read.table("METAL_AWIGen.txt", header = TRUE)

# Convert p-values to scientific notation with consistent formatting
dataset1$PVALUE <- formatC(dataset1$PVALUE, format = "e", digits = 10)
dataset2$PVALUE <- formatC(dataset2$PVALUE, format = "e", digits = 10)

# Save the standardized datasets
write.table(dataset1, "METAL_GIANT_standardized.txt", row.names = FALSE, quote = FALSE)
write.table(dataset2, "METAL_AWIGen_standardized.txt", row.names = FALSE, quote = FALSE)

####Performing meta-analysis between GIANT and AWIGen using METAL######p values and sample size

MARKER SNP
ALLELE REF_ALLELE OTHER_ALLELE
EFFECT EFFECT1
PVALUE PVALUE
WEIGHT N

PROCESS METAL_GIANT.txt
PROCESS METAL_AWIGen.txt

OUTFILE METAANALYSIS_METAL_AWIGen_standardized.txt-METAL_GIANT_standardized.txt_ .tbl
ANALYZE

ANALYZE HETEROGENEITY

## In R Read results
setwd("C:/Users/raylt/Documents/GWAS/generic-metal")

file_path <- "METAANALYSIS_METAL_AWIGen_standardized.txt-METAL_GIANT_standardized.txt_ .tbl"

file_contents <- readLines(file_path)

head(file_contents, n = 10)

# Attempt to read the file as a table (assuming tab-separated values)
info_df <- read.table(file_path, header = TRUE, sep = "\t", stringsAsFactors = FALSE)

# View the data frame structure
str(info_df)

# View the first few rows
head(info_df)

file_contents <- readLines(file_path)

head(file_contents, n = 10)

# Read the file as a table
info_df <- read.table(file_path, header = TRUE, sep = "\t", stringsAsFactors = FALSE)

# View the data frame structure
str(info_df)

# View the first few rows
head(info_df)


# renaming columns
# Trim spaces and then rename Markername and P.value columns
colnames(info_df) <- trimws(colnames(info_df))
colnames(info_df)[colnames(info_df) == 'MarkerName'] <- 'rsid'

colnames(info_df) <- trimws(colnames(info_df))
colnames(info_df)[colnames(info_df) == 'P.value'] <- 'pval'


#LD clumping
clumped_results_info_df <- ld_clump(
  dat = info_df,
  plink_bin = plink_bin_path,
  bfile = bfile_path, pop = "AFR"
)

# Export the data frame to a CSV file
output_file_path <- "METAANALYSIS.LD_SNPS.csv"
write.csv(clumped_results_info_df, file = output_file_path, row.names = FALSE)

##Heterogeneity
# Define the fixed effects meta-analysis function
fixed_effects_meta_analysis <- function(beta_vec, se_vec) 
  {
  w <- 1 / se_vec^2  # Calculate weights
  beta <- sum(beta_vec * w) / sum(w)  # Calculate meta-analysis beta
  se <- sqrt(1 / sum(w))  # Calculate standard error of the combined beta
  pval <- pnorm(abs(beta / se), lower.tail = FALSE)  # Calculate p-value for combined beta
  Qj <- w * (beta - beta_vec)^2  # Calculate Cochran's Q for each study
  Q <- sum(Qj)  # Total Q statistic
  Qdf <- length(beta_vec) - 1  # Degrees of freedom for Q statistic
  Qjpval <- pchisq(Qj, 1, lower.tail = FALSE)  # Per-study heterogeneity p-values
  Qpval <- pchisq(Q, Qdf, lower.tail = FALSE)  # Cochran's Q p-value
  return(list(beta = beta, se = se, Qpval = Qpval, Qj = Qj, Qjpval = Qjpval))
}

# Define the heterogeneity test function
heterogeneity_test <- function(sslist) {
  # Extract betas and standard errors for each population
  b <- lapply(sslist, \(x) x$bhat) %>% bind_cols
  se <- lapply(sslist, \(x) x$se) %>% bind_cols
  
  # Apply fixed effects meta-analysis to each SNP
  o <- lapply(1:nrow(b), \(i) {
    fixed_effects_meta_analysis(as.numeric(b[i,]), as.numeric(se[i,]))
  })
  
  # Create output tables for Cochran's Q and per-population heterogeneity p-values
  Q <- tibble(snp = sslist[[1]]$snp, Qpval = sapply(o, \(x) x$Qpval))
  Qj <- lapply(o, \(x) x$Qjpval) %>% do.call(rbind, .) %>% 
    as_tibble() %>%
    rename(setNames(paste0("V", 1:length(sslist)), names(sslist))) %>%
    mutate(snp = sslist[[1]]$snp)
  
  return(list(Q = Q, Qj = Qj))
}

# Find common SNPs
common_snps <- intersect(clumped_AWIGenresults$snp, clumped_GIANTresults$snp)



            
